# ==========================================
# SentinAI Configuration
# Run 'npm run setup' for guided setup.
# ==========================================

# === REQUIRED ===
L2_RPC_URL=https://your-l2-rpc-endpoint.com

# === AI Provider (하나 이상 선택, 우선순위: Qwen > Claude > GPT > Gemini) ===
QWEN_API_KEY=your-qwen-api-key-here
# ANTHROPIC_API_KEY=sk-ant-...
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=AIza...
# AI_GATEWAY_URL=https://your-gateway.com           # (선택) 모든 AI 요청을 게이트웨이/프록시 경유

# === K8s Monitoring (Optional) ===
# Set AWS_CLUSTER_NAME only — K8S_API_URL and region are auto-detected.
# AWS auth: use 'aws configure' or IAM Role (no credentials needed in .env)
AWS_CLUSTER_NAME=my-cluster-name
# K8S_NAMESPACE=default
# K8S_APP_PREFIX=op

# === State Store (Optional) ===
# Enables Redis-backed state persistence. If not set, uses in-memory (resets on restart).
# REDIS_URL=redis://localhost:6379

# === Alert (Optional) ===
# ALERT_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL   # 이상 탐지 알림 웹훅

# === Cost Tracking (Optional) ===
# COST_TRACKING_ENABLED=true   # vCPU 사용 패턴 추적 (기본: 활성화, false로 비활성화)

# === Cloudflare Tunnel (Optional) ===
# HTTPS + 인증으로 대시보드 공개. docker compose --profile tunnel up -d 로 활성화.
# 설정: https://one.dash.cloudflare.com → Networks → Tunnels → Token 복사
# CLOUDFLARE_TUNNEL_TOKEN=eyJhIjoiYWJj...

# === Agent Loop (Optional) ===
# AGENT_LOOP_ENABLED=true    # Server-side autonomous loop (auto-enabled if L2_RPC_URL is set)
# AUTO_REMEDIATION_ENABLED=true  # Layer 4 auto-remediation (disabled by default)

# === EOA Balance Monitoring (Optional) ===
# Monitor batcher/proposer L1 ETH balances and auto-refill from treasury.
#
# EOA Address Configuration (priority order):
# 1. Manual EOA addresses (if you know the addresses)
#    BATCHER_EOA_ADDRESS=0x...     # Batcher EOA address to monitor
#    PROPOSER_EOA_ADDRESS=0x...    # Proposer EOA address to monitor
#
# 2. Private key derivation (derive EOA from private key, no L1 RPC required)
#    BATCHER_PRIVATE_KEY=0x...     # Batcher private key → derive EOA address
#    PROPOSER_PRIVATE_KEY=0x...    # Proposer private key → derive EOA address
#
# Auto-refill Configuration (requires treasury wallet):
# TREASURY_PRIVATE_KEY=0x...    # Treasury wallet private key for auto-refill (omit for monitor-only)
# EOA_BALANCE_WARNING_ETH=0.5   # Warning threshold (default: 0.5 ETH)
# EOA_BALANCE_CRITICAL_ETH=0.1  # Critical threshold — triggers auto-refill + escalation (default: 0.1 ETH)
#
# Advanced refill tuning (defaults are usually fine):
# EOA_REFILL_AMOUNT_ETH=1.0     # Amount to send per refill (default: 1.0 ETH)
# EOA_REFILL_MAX_DAILY_ETH=5    # Daily refill cap (default: 5 ETH)
# EOA_REFILL_COOLDOWN_MIN=10    # Cooldown between refills per EOA (default: 10 min)
# EOA_GAS_GUARD_GWEI=100        # Skip refill if L1 gas > this (default: 100 gwei)
# EOA_TREASURY_MIN_ETH=1.0      # Min treasury balance to allow refill (default: 1.0 ETH)

# === L1 RPC for SentinAI (Optional) ===
# SentinAI monitoring & analytics use public L1 RPC endpoints.
# L2 nodes (op-node, op-batcher, op-proposer) use SEPARATE L1 RPC via Proxyd (see proxyd-failover-setup.md).
#
# For SentinAI: Use comma-separated public RPC endpoints with automatic failover.
# Spare L1 RPC endpoints for 429 failover.
# When L2 nodes hit 429 errors 10x consecutively, SentinAI swaps to the next URL from this list.
# Falls back to publicnode.com if not set.
# L1_RPC_URLS=https://ethereum-sepolia-rpc.publicnode.com,https://sepolia.drpc.org,https://rpc.sepolia.org
#
# For L2 nodes: Configure via L1 Proxyd (separate from SentinAI)
# See docs/guide/proxyd-failover-setup.md for Proxyd configuration
# K8S_APP_PREFIX is also used for StatefulSet names and ConfigMap lookups (unified prefix)

# === L1 Proxyd Integration (Optional) ===
# Enable when op-node/batcher/proposer connect to L1 through Proxyd (eth-optimism/infra).
# When enabled, failover updates Proxyd ConfigMap TOML before updating StatefulSet env vars.
# L1_PROXYD_ENABLED=false                        # Enable Proxyd integration (y/n in wizard)
# L1_PROXYD_CONFIGMAP_NAME=proxyd-config        # ConfigMap name (default: proxyd-config)
# L1_PROXYD_DATA_KEY=proxyd.toml                 # TOML key in ConfigMap (default: proxyd.toml)
# L1_PROXYD_UPSTREAM_GROUP=main                  # Upstream group to update (default: main)
# L1_PROXYD_UPDATE_MODE=replace                  # replace (update URL) | append (add new + rotate)
# (L1_PROXYD_SPARE_URLS is deprecated — use L1_RPC_URLS instead)

# === LLM Stress Test Framework (Optional) ===
# Configure API server endpoints for LLM benchmarking tests.
# If not set, uses default endpoints (OpenAI, DashScope, Anthropic, Google).
# Useful for testing against custom/local API servers or proxies.
#
# Test execution: npx tsx src/lib/__tests__/llm-stress-test/index.ts
# Output: src/lib/__tests__/llm-stress-test/output/report-*.md (Markdown) + results-*.json (JSON)
#
# API Server Configuration (custom endpoints):
# LLM_TEST_QWEN_URL=https://dashscope.aliyuncs.com/compatible-mode  # Qwen API (OpenAI compatible)
# LLM_TEST_ANTHROPIC_URL=https://api.anthropic.com                  # Anthropic API
# LLM_TEST_OPENAI_URL=https://api.openai.com                        # OpenAI API
# LLM_TEST_GEMINI_URL=https://generativelanguage.googleapis.com      # Gemini API
#
# Proxy Configuration (LiteLLM Gateway or similar):
# LLM_TEST_PROXY_URL=http://localhost:4000                          # LiteLLM Gateway or custom proxy
# LLM_TEST_PROXY_ENABLED=false                                      # Route all requests through proxy
#
# Test Execution Configuration:
# LLM_TEST_PROVIDERS=qwen,anthropic,openai,gemini                   # Providers to test (comma-separated)
# LLM_TEST_TIMEOUT_FAST=30000                                       # Fast-tier request timeout (ms)
# LLM_TEST_TIMEOUT_BEST=60000                                       # Best-tier request timeout (ms)
# LLM_TEST_PARALLELISM_DEFAULT=5                                    # Default concurrent requests
# LLM_TEST_OUTPUT_DIR=src/lib/__tests__/llm-stress-test/output      # Result output directory

# === Advanced (usually not needed) ===
# AI_GATEWAY_URL=https://api.ai.tokamak.network  # LiteLLM Gateway (설정 시 직접 API 대신 Gateway 사용)
# K8S_API_URL=https://...    # Override auto-detection
# K8S_INSECURE_TLS=true      # Skip TLS verification (dev/self-signed certs only)
